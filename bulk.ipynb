{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flox.util import key_chain\n",
    "\n",
    "\n",
    "seed = 42\n",
    "chain = key_chain(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "num_particles = 100\n",
    "\n",
    "dmin = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from flox.geom import Torus\n",
    "\n",
    "torus = Torus(jnp.ones(dim))\n",
    "\n",
    "sigma = jnp.power(2, 1./6.) * dmin\n",
    "soften = 1e-5\n",
    "\n",
    "lennard_jones_potential = flox.bulk.pairwise_penalty(\n",
    "    partial(flox.bulk.lennard_jones_edge, sigma=sigma, soften=soften),\n",
    "    torus\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_dataclasses import pytree_dataclass\n",
    "\n",
    "from jaxtyping import Float, Array\n",
    "\n",
    "from flox._src.flow.api import Transformed  # type: ignore\n",
    "\n",
    "Particles = Float[Array, \"P D\"]\n",
    "Auxiliaries = Float[Array, \"P F\"]\n",
    "\n",
    "@pytree_dataclass(frozen=True)\n",
    "class State:\n",
    "    p: jnp.ndarray\n",
    "    q0: jnp.ndarray\n",
    "    q1: jnp.ndarray\n",
    "\n",
    "\n",
    "def sample_base(key, num_particles, dim):\n",
    "    chain = key_chain(key)\n",
    "    p = jax.random.uniform(next(chain), shape=(num_particles, dim))\n",
    "    q0 = jax.random.normal(next(chain), shape=(num_particles, 1, dim))\n",
    "    q1 = jax.random.normal(next(chain), shape=(num_particles, 1, dim))\n",
    "    ldj = harmonic(q0) + harmonic(q1)\n",
    "    return Transformed(State(p, q0, q1), ldj)\n",
    "\n",
    "\n",
    "def harmonic(x):\n",
    "    return jnp.sum(0.5 * jnp.square(x))\n",
    "\n",
    "\n",
    "def base_potential(s: State):\n",
    "    return harmonic(s.q0) + harmonic(s.q1)\n",
    "\n",
    "\n",
    "def target_potential(s: State):\n",
    "    return lennard_jones_potential(s.p) + harmonic(s.q0) + harmonic(s.q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast\n",
    "import haiku as hk\n",
    "\n",
    "from flox._src.bulk.lattice import AggregationMethod, neighbors\n",
    "\n",
    "def indices_and_weights(pos, resolution):\n",
    "    idx = jax.vmap(flox.bulk.lattice_indices, in_axes=(0, None, None))(pos, flox.bulk.neighbors(pos.shape[-1]), resolution)\n",
    "    weights = jax.vmap(flox.bulk.lattice_weights, in_axes=(0, 0, None))(pos, idx, resolution)\n",
    "    return idx, weights\n",
    "\n",
    "\n",
    "class GaugeConvNet(hk.Module):\n",
    "\n",
    "    def __init__(self, num_out, resolution):\n",
    "        super().__init__()\n",
    "        self.num_out = num_out\n",
    "        self.resolution = resolution\n",
    "\n",
    "    def __call__(self, idx, weights, sig):\n",
    "        dim = sig.shape[-1]\n",
    "        kernel = hk.get_parameter(\n",
    "            \"kernel\",\n",
    "            shape=(3 ** dim, sig.shape[-2], self.num_out),\n",
    "            init=hk.initializers.TruncatedNormal()\n",
    "        )\n",
    "        # bias = hk.get_parameter(\n",
    "        #     \"bias\", shape=(self.num_out, 1),\n",
    "        #     init=hk.initializers.Constant(0.)\n",
    "        # )\n",
    "        sig = flox.bulk.scatter(sig, weights, idx, self.resolution)\n",
    "        other = flox.bulk.gather(sig, idx, AggregationMethod.Nothing)\n",
    "        focus = cast(Array, other[:, 4])\n",
    "        out = jax.vmap(flox.bulk.gauge_conv, in_axes=(0, 0, None, None))(\n",
    "            focus, other, neighbors(dim), kernel\n",
    "        ) #+ bias\n",
    "        return out\n",
    "\n",
    "\n",
    "class Linear(hk.Module):\n",
    "    \n",
    "    def __init__(self, num_out):\n",
    "        super().__init__()\n",
    "        self.num_out = num_out\n",
    "\n",
    "    def __call__(self, x):\n",
    "        stddev = 1./jnp.sqrt(x.shape[-2] + self.num_out)\n",
    "        w = hk.get_parameter(\n",
    "            \"weight\",\n",
    "            shape=(x.shape[-2], self.num_out),\n",
    "            init=hk.initializers.TruncatedNormal(stddev=stddev))\n",
    "        return jnp.einsum(\"...fd, fg -> ...gd\", x, w)\n",
    "\n",
    "\n",
    "class GaugeResNet(hk.Module):\n",
    "\n",
    "    def __init__(self, num_layers, num_hidden, num_out, resolution, activation, output_residual):\n",
    "        super().__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.resolution = resolution\n",
    "        self.activation = activation\n",
    "        self.num_layers = num_layers\n",
    "        self.num_out = num_out\n",
    "        self.output_residual = output_residual\n",
    "\n",
    "    def __call__(self, idx, weights, signal):\n",
    "        def body(signal) -> Array:\n",
    "            out = GaugeConvNet(self.num_hidden, self.resolution)(idx, weights, signal)\n",
    "            return signal + self.activation(out)\n",
    "\n",
    "        out = Linear(self.num_hidden)(signal)\n",
    "        out = hk.experimental.layer_stack(self.num_layers)(body)(out)\n",
    "        out = Linear(self.num_out)(out)\n",
    "        if self.output_residual:\n",
    "            if signal.shape[-2] in (self.num_out, 1):\n",
    "                return signal + out\n",
    "            else:\n",
    "                raise ValueError(f\"Cannot broadcast output residual.\"\\\n",
    "                                 f\"Input channels: {signal.shape[-2]}, \"\\\n",
    "                                 f\"Oututput channels: {self.num_out}.\")\n",
    "        else:\n",
    "            return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from flox._src.flow.api import Transformed\n",
    "from flox._src.geom.manifold import Manifold, PointN\n",
    "from flox.flow import Affine, Lambda\n",
    "\n",
    "def indices_and_weights(pos, resolution):\n",
    "    idx = jax.vmap(flox.bulk.lattice_indices, in_axes=(0, None, None))(pos, flox.bulk.neighbors(pos.shape[-1]), resolution)\n",
    "    weights = jax.vmap(flox.bulk.lattice_weights, in_axes=(0, 0, None))(pos, idx, resolution)\n",
    "    return idx, weights\n",
    "\n",
    "class AuxUpdater(hk.Module):\n",
    "\n",
    "    def __init__(self, field, num_layers, num_hidden, num_out, resolution, activation):\n",
    "        super().__init__()\n",
    "        self.field = field\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_out = num_out\n",
    "        self.resolution = resolution\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, state: State):\n",
    "        idx, weights = indices_and_weights(state.p, self.resolution)\n",
    "        params = GaugeResNet(\n",
    "            self.num_layers,\n",
    "            self.num_hidden,\n",
    "            self.num_out,\n",
    "            self.resolution,\n",
    "            self.activation,\n",
    "            True\n",
    "        )(idx, weights, self.field(state))\n",
    "        shift, scale = jnp.split(params, 2, axis=-2)\n",
    "        shift = shift.sum(axis=-2, keepdims=True) * 1e-4\n",
    "        scale = jnp.sqrt(1e-12 + jnp.square(scale.sum(axis=-2, keepdims=True)).sum(axis=-1, keepdims=True)) * 1e-4\n",
    "        return Affine(shift, scale)\n",
    "\n",
    "class PosUpdater(hk.Module):\n",
    "\n",
    "    def __init__(self, manifold: Manifold, init_scale: float=1e-3):\n",
    "        super().__init__()\n",
    "        self.manifold = manifold\n",
    "        self.init_scale = init_scale\n",
    "\n",
    "    def __call__(self, state: State) -> Lambda[PointN, PointN]:\n",
    "        shift = state.q0.sum(axis=-2) * self.init_scale\n",
    "        \n",
    "        def shift_fn(x, shift) -> Transformed[PointN]:\n",
    "            return Transformed(self.manifold.shift(x, shift), jnp.zeros(()))\n",
    "        \n",
    "        return Lambda(\n",
    "            forward=lambda x: shift_fn(x, shift),\n",
    "            inverse=lambda x: shift_fn(x, -shift)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "relax = flox.bulk.relax(\n",
    "    torus.shift,\n",
    "    flox.bulk.pairwise_penalty(\n",
    "        partial(flox.bulk.soft_edge, dmin=dmin),\n",
    "        torus\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import lenses\n",
    "from flox._src.flow.api import Transform\n",
    "from flox._src.flow.impl import Affine\n",
    "from flox._src.util.func import Lens\n",
    "from flox.bulk import gauge_conv\n",
    "import flox.nn as fnn\n",
    "\n",
    "class Relaxation(hk.Module):\n",
    "    def __call__(self, s: State):\n",
    "        _, dq = relax(s.p)\n",
    "        dq = dq[..., None, :]\n",
    "        return Affine(dq, jnp.zeros_like(dq))\n",
    "\n",
    "\n",
    "def get_q0(state: State):\n",
    "    return state.q0\n",
    "\n",
    "def update_q0(state: State, new):\n",
    "    return lenses.bind(state).q0.set(new)\n",
    "\n",
    "def get_q1(state: State):\n",
    "    return state.q1\n",
    "\n",
    "def update_q1(state: State, new):\n",
    "    return lenses.bind(state).q1.set(new)\n",
    "\n",
    "def get_pos(state: State):\n",
    "    return state.p\n",
    "\n",
    "def update_pos(state: State, new):\n",
    "    return lenses.bind(state).p.set(new)\n",
    "\n",
    "\n",
    "def make_aux_coupling() -> Transform[State, State]:\n",
    "    return flox.flow.Pipe([\n",
    "        flox.flow.SimpleCoupling(\n",
    "            AuxUpdater(\n",
    "                get_q0,\n",
    "                2, 64, 2, (32, 32), jax.nn.silu,\n",
    "            ),\n",
    "            Lens(get_q1, update_q1)\n",
    "        ),\n",
    "        flox.flow.SimpleCoupling(\n",
    "            AuxUpdater(\n",
    "                get_q1,\n",
    "                2, 64, 2, (32, 32), jax.nn.silu,\n",
    "            ),\n",
    "            Lens(get_q0, update_q0)\n",
    "        )\n",
    "\n",
    "    ])\n",
    "\n",
    "def make_inner_flow(num_blocks) -> Transform[State, State]:\n",
    "    return flox.flow.Pipe([\n",
    "        flox.nn.haiku.LayerStack(make_aux_coupling, num_layers=num_blocks),\n",
    "        flox.flow.SimpleCoupling(\n",
    "            PosUpdater(torus),\n",
    "            Lens(get_pos, update_pos)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "def make_full_flow(num_blocks) -> Transform[State, State]:\n",
    "    return flox.flow.Pipe([\n",
    "        flox.flow.SimpleCoupling(\n",
    "            Relaxation(),\n",
    "            Lens(get_q0, update_q0)\n",
    "        ),\n",
    "        make_inner_flow(num_blocks),\n",
    "    ])\n",
    "\n",
    "flow = flox.nn.haiku.to_haiku(partial(make_full_flow, num_blocks=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flox.flow import Transformed \n",
    "\n",
    "num_particles = 100\n",
    "\n",
    "p = jax.random.uniform(next(chain), shape=(num_particles, dim))\n",
    "q0 = jax.random.normal(next(chain), shape=(num_particles, 1, dim)) * 1e-3\n",
    "q1 = jax.random.normal(next(chain), shape=(num_particles, 1, dim)) * 1e-3\n",
    "\n",
    "params = jax.jit(flow.pure.init)(\n",
    "    next(chain),\n",
    "    State(p, q0, q1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = jax.random.uniform(next(chain), shape=(num_particles, dim))\n",
    "q0 = jax.random.normal(next(chain), shape=(num_particles, 1, dim)) * 1e-3\n",
    "q1 = jax.random.normal(next(chain), shape=(num_particles, 1, dim)) * 1e-3\n",
    "\n",
    "out = jax.jit(flow.with_params(params).forward)(\n",
    "    State(p, q0, q1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "NUM_ITERS = 3_000\n",
    "PLOT_INTERVAL = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "optim = optax.adam(learning_rate=LEARNING_RATE)\n",
    "opt_state = optim.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flox.nn import train\n",
    "from flox.flow import DatasetSampler\n",
    "\n",
    "step = train.mle_step(base_potential, flow, optim, partial(sample_base, num_particles=num_particles, dim=dim), 128)\n",
    "step = jax.jit(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/3000 [00:00<?, ?it/s]2022-11-08 18:39:05.778271: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.19GiB (rounded to 7725497856)requested by op \n",
      "2022-11-08 18:39:05.778537: W external/org_tensorflow/tensorflow/tsl/framework/bfc_allocator.cc:492] *___________________________________________________________________________________________________\n",
      "2022-11-08 18:39:05.781858: E external/org_tensorflow/tensorflow/compiler/xla/pjrt/pjrt_stream_executor_client.cc:2153] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 7725497712 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:    3.38MiB\n",
      "              constant allocation:       172B\n",
      "        maybe_live_out allocation:    3.38MiB\n",
      "     preallocated temp allocation:    7.19GiB\n",
      "                 total allocation:    7.20GiB\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 1.10GiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: s32[2,2,128,100,9,64,2,5]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 1.10GiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2, 5) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: s32[2,2,128,100,9,64,2,5]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 450.00MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: s32[2,2,128,100,9,64,4]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 450.00MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 4) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: s32[2,2,128,100,9,64,4]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 5:\n",
      "\t\tSize: 225.00MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: f32[2,2,128,100,9,64,2]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 6:\n",
      "\t\tSize: 225.00MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: f32[2,2,128,100,9,64,2]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 7:\n",
      "\t\tSize: 225.00MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: f32[2,2,128,100,9,64,2]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 8:\n",
      "\t\tSize: 225.00MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: f32[2,2,128,100,9,64,2]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 9:\n",
      "\t\tSize: 112.50MiB\n",
      "\t\tXLA Label: copy\n",
      "\t\tShape: f32[2,2,128,100,9,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 10:\n",
      "\t\tSize: 112.50MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n",
      "\t\tXLA Label: broadcast\n",
      "\t\tShape: f32[2,2,128,100,9,64]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 11:\n",
      "\t\tSize: 56.25MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n",
      "\t\tXLA Label: iota\n",
      "\t\tShape: s32[128,100,9,64,2,1]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 12:\n",
      "\t\tSize: 56.25MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n",
      "\t\tXLA Label: iota\n",
      "\t\tShape: s32[128,100,9,64,2,1]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 13:\n",
      "\t\tSize: 56.25MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n",
      "\t\tXLA Label: iota\n",
      "\t\tShape: s32[128,100,9,64,2,1]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 14:\n",
      "\t\tSize: 56.25MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/iota[dtype=int32 shape=(128, 100, 9, 64, 2, 1) dimension=0]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n",
      "\t\tXLA Label: iota\n",
      "\t\tShape: s32[128,100,9,64,2,1]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 15:\n",
      "\t\tSize: 56.25MiB\n",
      "\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 2, 9, 64) broadcast_dimensions=(1, 2, 3, 4)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=230\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[128,100,2,9,64]\n",
      "\t\t==========================\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                               | 0/3000 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 7725497712 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    3.38MiB\n              constant allocation:       172B\n        maybe_live_out allocation:    3.38MiB\n     preallocated temp allocation:    7.19GiB\n                 total allocation:    7.20GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.10GiB\n\t\tXLA Label: copy\n\t\tShape: s32[2,2,128,100,9,64,2,5]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2, 5) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: s32[2,2,128,100,9,64,2,5]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 450.00MiB\n\t\tXLA Label: copy\n\t\tShape: s32[2,2,128,100,9,64,4]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 450.00MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 4) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: fusion\n\t\tShape: s32[2,2,128,100,9,64,4]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 225.00MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 112.50MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 112.50MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: f32[2,2,128,100,9,64]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/iota[dtype=int32 shape=(128, 100, 9, 64, 2, 1) dimension=0]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 2, 9, 64) broadcast_dimensions=(1, 2, 3, 4)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=230\n\t\tXLA Label: fusion\n\t\tShape: f32[128,100,2,9,64]\n\t\t==========================\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m---> 14\u001b[0m     loss, params, opt_state \u001b[39m=\u001b[39m step(\u001b[39mnext\u001b[39;49m(chain), params, opt_state)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     agg_loss \u001b[39m=\u001b[39m agg_loss\u001b[39m.\u001b[39mupdate(loss)\n\u001b[1;32m     16\u001b[0m     losses\u001b[39m.\u001b[39mappend(agg_loss\u001b[39m.\u001b[39mvalue)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/jax/_src/dispatch.py:895\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handler, has_unordered_effects, ordered_effects, kept_var_idx, has_host_callbacks, *args)\u001b[0m\n\u001b[1;32m    893\u001b[0m     runtime_token \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m   out_flat \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39;49mexecute(in_flat)\n\u001b[1;32m    896\u001b[0m check_special(name, out_flat)\n\u001b[1;32m    897\u001b[0m out_bufs \u001b[39m=\u001b[39m unflatten(out_flat, output_buffer_counts)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 7725497712 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:    3.38MiB\n              constant allocation:       172B\n        maybe_live_out allocation:    3.38MiB\n     preallocated temp allocation:    7.19GiB\n                 total allocation:    7.20GiB\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 1.10GiB\n\t\tXLA Label: copy\n\t\tShape: s32[2,2,128,100,9,64,2,5]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 1.10GiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2, 5) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: s32[2,2,128,100,9,64,2,5]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 450.00MiB\n\t\tXLA Label: copy\n\t\tShape: s32[2,2,128,100,9,64,4]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 450.00MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 4) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: fusion\n\t\tShape: s32[2,2,128,100,9,64,4]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 225.00MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 225.00MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64, 2) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: f32[2,2,128,100,9,64,2]\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 112.50MiB\n\t\tXLA Label: copy\n\t\tShape: f32[2,2,128,100,9,64]\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 112.50MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/jvp(vmap(inverse))/stacked/_apply/stacked/layer_stack/broadcast_in_dim[shape=(2, 2, 128, 100, 9, 64) broadcast_dimensions=()]\" source_file=\"/storage/mi/jonkhler/miniconda3/envs/py310/lib/python3.10/site-packages/haiku/_src/layer_stack.py\" source_line=121\n\t\tXLA Label: broadcast\n\t\tShape: f32[2,2,128,100,9,64]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 13:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 9, 64, 2, 1) broadcast_dimensions=(1, 2, 3, 4, 5)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 14:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/iota[dtype=int32 shape=(128, 100, 9, 64, 2, 1) dimension=0]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=231\n\t\tXLA Label: iota\n\t\tShape: s32[128,100,9,64,2,1]\n\t\t==========================\n\n\tBuffer 15:\n\t\tSize: 56.25MiB\n\t\tOperator: op_name=\"jit(jitted_step)/jit(main)/jit(jitted_step)/gauge_conv_net/broadcast_in_dim[shape=(128, 100, 2, 9, 64) broadcast_dimensions=(1, 2, 3, 4)]\" source_file=\"/storage/mi/jonkhler/PhD/flox/flox/_src/bulk/convolution.py\" source_line=230\n\t\tXLA Label: fusion\n\t\tShape: f32[128,100,2,9,64]\n\t\t==========================\n\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from IPython import display  # type: ignore\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt  # type: ignore\n",
    "from tqdm import tqdm\n",
    "\n",
    "pbar = tqdm(range(NUM_ITERS))\n",
    "agg_loss = train.RunningMean(0., 0)\n",
    "losses = []\n",
    "\n",
    "\n",
    "for i in pbar:\n",
    "    \n",
    "    loss, params, opt_state = step(next(chain), params, opt_state)  # type: ignore\n",
    "    agg_loss = agg_loss.update(loss)\n",
    "    losses.append(agg_loss.value)\n",
    "    \n",
    "    pbar.set_description(f\"loss: {agg_loss.value:.4}\")\n",
    "    if not i % PLOT_INTERVAL:\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        plt.plot(losses)\n",
    "        plt.ylabel(\"NLL\")\n",
    "        plt.xlabel(\"#iters\")\n",
    "    \n",
    "        plt.show()\n",
    "        time.sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc3f0728370>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(*out.obj.p.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1b6e97da93df4710d419de16df68eb92ecab97f41c13fcb5d93100dfb1d2aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
